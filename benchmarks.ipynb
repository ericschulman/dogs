{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import ensemble, preprocessing\n",
    "import xgboost as xgb\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training and test datasets\n",
    "train_raw = pd.read_csv('input/train_set.csv', parse_dates=[2,])\n",
    "test_raw = pd.read_csv('input/test_set.csv', parse_dates=[3,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2:  0.135932177588306\n",
      "MSE:  55312.24146055766\n"
     ]
    }
   ],
   "source": [
    "#regular model\n",
    "ols_data = train_raw.copy()\n",
    "ols_data['year'] = train_raw.quote_date.dt.year\n",
    "\n",
    "baseline_ols = smf.ols('cost ~ annual_usage + min_order_quantity + bracket_pricing + quantity + \\\n",
    "                       year + supplier', data = ols_data)\n",
    "\n",
    "\n",
    "baseline_fit = baseline_ols.fit()\n",
    "print('R2: ', baseline_fit.rsquared)\n",
    "print('MSE: ', baseline_fit.mse_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-fd201397c37c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m point = dict(ols_data[['annual_usage','min_order_quantity', 'bracket_pricing',\n\u001b[0;32m----> 2\u001b[0;31m                        'quantity','year','supplier']].loc[index])\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseline_fit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mols_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cost'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'index' is not defined"
     ]
    }
   ],
   "source": [
    "point = dict(ols_data[['annual_usage','min_order_quantity', 'bracket_pricing',\n",
    "                       'quantity','year','supplier']].loc[index])\n",
    "\n",
    "print(baseline_fit.predict(exog=point))\n",
    "print(ols_data['cost'].loc[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regular model\n",
    "ols_data = train_raw.copy()\n",
    "ols_data['year'] = train_raw.quote_date.dt.year\n",
    "print(ols_data.columns)\n",
    "\n",
    "baseline_ols = smf.ols('np.log(cost) ~  np.log(quantity) + annual_usage +  min_order_quantity + bracket_pricing  + \\\n",
    "+ supplier', data = ols_data)\n",
    "baseline_fit = baseline_ols.fit()\n",
    "print('AIC: %s, R2: %s, params: %s'%(baseline_fit.aic, baseline_fit.rsquared,baseline_fit.params.shape))\n",
    "print('quantity %s'%baseline_fit.params[2])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIC: 60694.38665779629, R2: 0.4920089391614567, params: (117,)\n",
      "<F test: F=array([[3432.14215417]]), p=0.0, df_denom=30121, df_num=60>\n",
      "quantity -83.7918929496086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erichschulman/anaconda3/lib/python3.7/site-packages/statsmodels/base/model.py:1532: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 61, but rank is 60\n",
      "  'rank is %d' % (J, J_), ValueWarning)\n"
     ]
    }
   ],
   "source": [
    "squaredterm_ols = smf.ols('np.log(cost) ~ np.log(quantity) + annual_usage +  min_order_quantity + bracket_pricing  + \\\n",
    "                        supplier + supplier*np.log(quantity) ', data = ols_data)\n",
    "\n",
    "squaredterm_fit = squaredterm_ols.fit()\n",
    "print('AIC: %s, R2: %s, params: %s'%( squaredterm_fit.aic, squaredterm_fit.rsquared,squaredterm_fit.params.shape))\n",
    "\n",
    "base_params = len(baseline_fit.params)\n",
    "restrict = len(squaredterm_fit.params)\n",
    "\n",
    "#run an f-test (might be wrong?)\n",
    "A = np.identity(restrict)\n",
    "A = A[:base_params-1,:]\n",
    "print(squaredterm_fit.f_test(A))\n",
    "print('quantity %s'%baseline_fit.params[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_raw.copy()\n",
    "test = test_raw.copy()\n",
    "\n",
    "# create some new features\n",
    "train['year'] = train.quote_date.dt.year\n",
    "train['month'] = train.quote_date.dt.month\n",
    "train['dayofyear'] = train.quote_date.dt.dayofyear\n",
    "train['dayofweek'] = train.quote_date.dt.dayofweek\n",
    "train['day'] = train.quote_date.dt.day\n",
    "\n",
    "test['year'] = test.quote_date.dt.year\n",
    "test['month'] = test.quote_date.dt.month\n",
    "test['dayofyear'] = test.quote_date.dt.dayofyear\n",
    "test['dayofweek'] = test.quote_date.dt.dayofweek\n",
    "test['day'] = test.quote_date.dt.day\n",
    "\n",
    "# drop useless columns and create labels\n",
    "idx = test.id.values.astype(int)\n",
    "labels = train.cost.values\n",
    "\n",
    "test = test.drop(['id', 'tube_assembly_id', 'quote_date'], axis = 1)\n",
    "train = train.drop(['quote_date', 'cost', 'tube_assembly_id'], axis = 1)\n",
    "\n",
    "# convert data to numpy array\n",
    "column_names = list(train.columns)\n",
    "\n",
    "train = np.array(train)\n",
    "test = np.array(test)\n",
    "\n",
    "# label encode the categorical variables\n",
    "for i in range(train.shape[1]):\n",
    "    if i in [0,3]:\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(train[:,i]) + list(test[:,i]))\n",
    "        train[:,i] = lbl.transform(train[:,i]) #give each label a number 1-67\n",
    "        test[:,i] = lbl.transform(test[:,i])\n",
    "        \n",
    "        \n",
    "# object array to float\n",
    "train = train.astype(float)\n",
    "test = test.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xgboost.core.DMatrix object at 0x7f1148324898>\n"
     ]
    }
   ],
   "source": [
    "label_log = np.log1p(labels)\n",
    "\n",
    "# fit a random forest model\n",
    "params = {}\n",
    "params[\"objective\"] = \"reg:linear\"\n",
    "params[\"eta\"] = 0.1\n",
    "params[\"min_child_weight\"] = 5\n",
    "params[\"subsample\"] = 1.0\n",
    "params[\"scale_pos_weight\"] = 1.0\n",
    "params[\"silent\"] = 1\n",
    "params[\"max_depth\"] = 7\n",
    "\n",
    "plst = list(params.items())\n",
    "\n",
    "xgtrain = xgb.DMatrix(train, label=label_log)\n",
    "xgtest = xgb.DMatrix(test)\n",
    "print(xgtest)\n",
    "\n",
    "\n",
    "num_rounds = 120\n",
    "model = xgb.train(plst, xgtrain, num_rounds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14370526453776553\n"
     ]
    }
   ],
   "source": [
    "mse = ( ( label_log - model.predict(xgtrain) )**2).sum()\n",
    "r2 = mse/(( label_log - label_log.mean() )**2).sum()\n",
    "\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.6555067]\n",
      "4.6877695119712\n"
     ]
    }
   ],
   "source": [
    "#predict a point\n",
    "\n",
    "index = 3\n",
    "point  = train[index,:].reshape(1,len(train[index,:]))\n",
    "print(model.predict(xgb.DMatrix(point)))\n",
    "print(labels[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions from the model, convert them and dump them!\n",
    "preds = np.expm1(model.predict(xgtest))\n",
    "preds = pd.DataFrame({\"id\": idx, \"cost\": preds})\n",
    "preds.to_csv('benchmark.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
